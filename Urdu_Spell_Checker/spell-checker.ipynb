{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "i18-0800.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "968JjfmvslsU"
      },
      "source": [
        "Name: Buraq Khan\n",
        "\n",
        "Email: i180800@nu.edu.pk\n",
        "\n",
        "Roll-num: 18I-0800\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI0BR3XjWprT"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ0-VFT2epvY"
      },
      "source": [
        "# File Reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OanPevKrKeY"
      },
      "source": [
        "**File Reading And Unigram Generation**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FvWHzcbnSES"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/nlp_a4/data.txt\") as f:\n",
        "  corpus = f.read().split()\n",
        "\n",
        "vocab = {}\n",
        "for word in corpus:\n",
        "  if word not in vocab:\n",
        "    vocab[word] = 1\n",
        "  else:\n",
        "    vocab[word] += 1\n",
        "\n",
        "unigrams = {}\n",
        "for key, value in vocab.items():\n",
        "  unigrams[key] = (value/len(corpus))\n",
        "\n",
        "# for word in unigrams:\n",
        "#   print(word, unigrams[word])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAmDg_i_UXPO"
      },
      "source": [
        "#corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU7XJBkkrPYV"
      },
      "source": [
        "**Misspelling Reading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZvsfQdwYKhs"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/nlp_a4/misspellings.txt\") as fr:\n",
        "  misspellings_raw = fr.readlines()\n",
        "\n",
        "for count, line  in enumerate(misspellings_raw):\n",
        "  line = re.sub('\\s+',' ', line)\n",
        "  misspellings_raw[count] = line\n",
        "\n",
        "for count, line in enumerate(misspellings_raw):\n",
        "  line = line.split()\n",
        "  misspellings_raw[count] = line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoDIc_rLcjpc"
      },
      "source": [
        "misspellings = {}\n",
        "for line in misspellings_raw:\n",
        "  word = line[0].replace(\",\" , \"\")\n",
        "  misspellings[word] = line[1:] \n",
        "\n",
        "# for key, value in misspellings.items():\n",
        "#   print(key, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7UcSYrerT1l"
      },
      "source": [
        "# Table Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO9Mupfmyrnl"
      },
      "source": [
        "del_dict = {}\n",
        "insert_dict = {}\n",
        "subs_dict = {}\n",
        "trans_dict = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPVWFHlKhlb7"
      },
      "source": [
        "**Insertion Table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnC-pHa6vdeq"
      },
      "source": [
        "def insert(word, error):\n",
        "  word_list = list(word)\n",
        "  error_list = list(error)\n",
        "\n",
        "  for count, char in enumerate(word_list):\n",
        "    \n",
        "    #handling special last char case\n",
        "    if count == len(word_list)-1:\n",
        "      if error_list[count] == char:\n",
        "        if (char, error_list[count+1]) in insert_dict.keys():\n",
        "          insert_dict[(char, error_list[count+1])] += 1\n",
        "        else:\n",
        "          insert_dict[(char, error_list[count+1])] = 1\n",
        "        break\n",
        "      else:\n",
        "        if (error_list[count], error_list[count+1]) in insert_dict.keys():\n",
        "          insert_dict[(error_list[count], error_list[count+1])] += 1\n",
        "        else:\n",
        "          insert_dict[(error_list[count], error_list[count+1])] = 1\n",
        "        break\n",
        "\n",
        "\n",
        "    if error_list[count] == char:\n",
        "      continue\n",
        "    else:\n",
        "      if count == 0:\n",
        "        if (\"#\", error_list[count]) in insert_dict.keys():\n",
        "          insert_dict[(\"#\", error_list[count])] += 1\n",
        "        else:\n",
        "          insert_dict[(\"#\", error_list[count])] = 1\n",
        "        break\n",
        "      else:  \n",
        "        if (error_list[count-1], error_list[count]) in insert_dict.keys():\n",
        "          insert_dict[(error_list[count-1], error_list[count])] += 1\n",
        "        else:\n",
        "          insert_dict[(error_list[count-1], error_list[count])] = 1\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxlrnNPohzTM"
      },
      "source": [
        "**Deletion Table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7pdqApUFD0T"
      },
      "source": [
        "def delete(word, error):\n",
        "  word_list = list(word)\n",
        "  error_list = list(error)\n",
        "\n",
        "  for count, char in enumerate(word_list):\n",
        "    \n",
        "    if count == len(word_list)-1:\n",
        "      if (word_list[count-1], char) in del_dict.keys():\n",
        "        del_dict[(word_list[count-1], char)] += 1\n",
        "      else:\n",
        "        del_dict[(word_list[count-1], char)] = 1\n",
        "      break\n",
        "    \n",
        "    if error_list[count] == char:\n",
        "      continue\n",
        "    \n",
        "    else:\n",
        "      if count == 0:\n",
        "        if (\"#\", char) in del_dict.keys():\n",
        "          del_dict[(\"#\", char)] += 1\n",
        "        else:\n",
        "          del_dict[(\"#\", char)] = 1\n",
        "        break\n",
        "      else:\n",
        "        if (char, error_list[count]) in del_dict.keys():\n",
        "          del_dict[(char, error_list[count])] += 1\n",
        "        else:\n",
        "          del_dict[(char, error_list[count])] = 1\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_HYcjx8h3IN"
      },
      "source": [
        "**Substitute and Transpose Tables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQk_yei3IbPL"
      },
      "source": [
        "def subsituteAndTranspose(word, error):\n",
        "  word_list = list(word)\n",
        "  error_list = list(error)\n",
        "\n",
        "  for count, char in enumerate(word_list):\n",
        "    if error_list[count] == char:\n",
        "      continue\n",
        "    else:\n",
        "      if count < len(word_list)-1:\n",
        "        if word_list[count+1] == error_list[count] and char == error_list[count+1]:\n",
        "          if (char,word_list[count+1]) in trans_dict:\n",
        "            trans_dict[(char, word_list[count+1])] += 1\n",
        "          else:\n",
        "            trans_dict[(char, word_list[count+1])] = 1\n",
        "          break\n",
        "    \n",
        "      if (char, error_list[count]) in subs_dict:\n",
        "        subs_dict[(char, error_list[count])] += 1\n",
        "      else:\n",
        "        subs_dict[(char, error_list[count])] = 1\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vS-LCLAsqm1"
      },
      "source": [
        "def findError(word, errors):\n",
        "  for error in errors:\n",
        "    if len(error) > len(word):\n",
        "      insert(word, error)\n",
        "    elif len(error) < len(word):\n",
        "      delete(word, error)\n",
        "    elif len(error) == len(word):\n",
        "      subsituteAndTranspose(word, error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udx3vIgioY6U"
      },
      "source": [
        "for key, value in misspellings.items():\n",
        "  word = key\n",
        "  error_words = value\n",
        "  findError(word, error_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIAY9GYuhmD9"
      },
      "source": [
        "**Channel Model Probability**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYk5MQ3FzZt8"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/nlp_a4/data.txt\") as f:\n",
        "  test = f.read()\n",
        "\n",
        "test = re.sub('\\s+',' ', test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRTJ33fpi3MB"
      },
      "source": [
        "char_dict = {}\n",
        "for char in test:\n",
        "  if char is not \" \":\n",
        "    if char in char_dict.keys():\n",
        "      char_dict[char] += 1\n",
        "    else:\n",
        "      char_dict[char] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FEqbj2QjLFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4701e5-3ed8-4a78-a512-ecb84f0b144b"
      },
      "source": [
        "char_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 61215602,\n",
              " 'b': 6203369,\n",
              " 'c': 2859542,\n",
              " 'd': 6035947,\n",
              " 'e': 16187901,\n",
              " 'f': 1594870,\n",
              " 'g': 3139263,\n",
              " 'h': 23399958,\n",
              " 'i': 21156833,\n",
              " 'j': 3116738,\n",
              " 'k': 15094087,\n",
              " 'l': 6741876,\n",
              " 'm': 8154672,\n",
              " 'n': 15830622,\n",
              " 'o': 10532080,\n",
              " 'p': 5393392,\n",
              " 'q': 1426466,\n",
              " 'r': 15514837,\n",
              " 's': 11123713,\n",
              " 't': 10417311,\n",
              " 'u': 6635599,\n",
              " 'v': 230208,\n",
              " 'w': 3549251,\n",
              " 'x': 32400,\n",
              " 'y': 6922251,\n",
              " 'z': 2363619}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIgXsZTdkk2A"
      },
      "source": [
        "bi_dict = {}\n",
        "for count, char in enumerate(test):\n",
        "  if count == len(test)-1:\n",
        "    break\n",
        "  else:\n",
        "    if char is not \" \" and test[count+1] is not \" \":\n",
        "      if (char, test[count+1]) in bi_dict.keys():\n",
        "        bi_dict[(char, test[count+1])] += 1\n",
        "      else:\n",
        "        bi_dict[(char, test[count+1])] = 1\n",
        "    elif char == \" \":\n",
        "      if (\"#\", test[count+1]) in bi_dict.keys():\n",
        "        bi_dict[(\"#\", test[count+1])] += 1\n",
        "      else:\n",
        "        bi_dict[(\"#\", test[count+1])] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wh4tq0arxW2"
      },
      "source": [
        "bi_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTC_ar_Wsnma"
      },
      "source": [
        "def calcErrorProbability(char_tuple, mode):\n",
        "  prob = float('-inf')\n",
        "  if mode == \"delete\":\n",
        "    if char_tuple in del_dict.keys():\n",
        "      prob = del_dict[char_tuple]/bi_dict[char_tuple]\n",
        "  elif mode == \"insert\":\n",
        "    if char_tuple[0] == \"#\":\n",
        "      prob = insert_dict[char_tuple]/len(corpus)\n",
        "    else:\n",
        "      if char_tuple in insert_dict.keys():\n",
        "        prob = insert_dict[char_tuple]/char_dict[char_tuple[0]]\n",
        "  elif mode == \"subsitute\":\n",
        "    if char_tuple in subs_dict.keys():\n",
        "      prob = subs_dict[char_tuple]/char_dict[char_tuple[0]]\n",
        "  elif mode == \"transpose\":\n",
        "    if char_tuple in trans_dict.keys():\n",
        "      prob = trans_dict[char_tuple]/bi_dict[char_tuple]\n",
        "\n",
        "  return prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdoWFL4Wy9ne",
        "outputId": "3143852d-49fe-4a05-a587-9fe6e6d36583"
      },
      "source": [
        "pr = calcErrorProbability((\"b\",\"c\"), \"subsitute\")\n",
        "pr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.257381271370444e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4_pHGKk5CXr"
      },
      "source": [
        "# Candidate Word Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxelmMdkKPm"
      },
      "source": [
        "**Candidate Words Generated Using Trie Data Structure**\n",
        "\n",
        "\n",
        "> Trie Data Structure has less space complexity and time complexity: O(n x m)\n",
        "\n",
        "\n",
        "> Searching done using levenstien's edit distance\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_uZBudX5KN6"
      },
      "source": [
        "class Trie():\n",
        "    def __init__(self):\n",
        "      self.child = {}\n",
        "      self.word = None\n",
        "\n",
        "    def insert(self, word):\n",
        "      node = self\n",
        "      for letter in word:\n",
        "        if letter not in node.child:\n",
        "          node.child[letter] = Trie()\n",
        "        node = node.child[letter]\n",
        "      node.word = word\n",
        "\n",
        "    def search(self, word, cost):\n",
        "      row = range(len(word) + 1)\n",
        "      word_list = []\n",
        "      for char in self.child:\n",
        "        self.searchCandidates(self.child[char], char, word, row, word_list, cost)\n",
        "      return word_list\n",
        "\n",
        "    def searchCandidates(self, node, char, word, prev_row, word_list, cost):\n",
        "      columns = len(word) + 1\n",
        "      curr_row = [prev_row[0] + 1]\n",
        "\n",
        "      for column in range(1, columns):\n",
        "        insert = curr_row[column - 1] + 1\n",
        "        delete = prev_row[column] + 1\n",
        "        if word[column - 1] != char:\n",
        "            replace = prev_row[column - 1] + 1\n",
        "        else:\n",
        "            replace = prev_row[column - 1]\n",
        "\n",
        "        curr_row.append(min(insert, delete, replace))\n",
        "\n",
        "      if curr_row[-1] <= cost and node.word is not None:\n",
        "        word_list.append((node.word, curr_row[-1]))\n",
        "\n",
        "      if min(curr_row) <= cost:\n",
        "        for char in node.child:\n",
        "          self.searchCandidates(node.child[char], char, word, curr_row, word_list, cost)\n",
        "\n",
        "def findTranspose(w_list, w):\n",
        "  trans_list = []\n",
        "  for tup in w_list:\n",
        "    check = 0\n",
        "    word = tup[0]\n",
        "    e_dist = tup[1]\n",
        "    if len(word) == len(w) and e_dist == 2:\n",
        "      for count, char in enumerate(word):\n",
        "        if char is not w[count]:\n",
        "          if char == w[count+1] and word[count+1] == w[count]:\n",
        "            if word[count+2:] == w[count+2:]:\n",
        "              trans_list.append(tup[0])\n",
        "          break\n",
        "  return trans_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IEzGsRUEvTm"
      },
      "source": [
        "trie = Trie()\n",
        "for word in unigrams.keys():\n",
        "  trie.insert(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUSXzR2GT7B1"
      },
      "source": [
        "def findCandidateWords(misspell_word):\n",
        "  candidate_words = []\n",
        "  test_list = []\n",
        "  word_list = trie.search(misspell_word, 2)\n",
        "  for val in word_list:\n",
        "    if val[1] == 1:\n",
        "      candidate_words.append(val[0])\n",
        "  test_list = findTranspose(word_list, misspell_word)\n",
        "  candidate_words.extend(test_list)\n",
        "  \n",
        "  return candidate_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gmf8PlH_lWr",
        "outputId": "09373e60-622b-4899-91da-b6fa81af4205"
      },
      "source": [
        "words = findCandidateWords(\"hello\")\n",
        "words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hell', 'helly', 'ello']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgxG-dBQBKrq"
      },
      "source": [
        "# Most Probable Word Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8yzpQc2GOV_"
      },
      "source": [
        "def checkDelete(correct_word, miss_word):\n",
        "  for count, char in enumerate(miss_word):\n",
        "    if count == len(miss_word)-1:\n",
        "      return (char, correct_word[count+1])\n",
        "    else:\n",
        "      if char == correct_word[count]:\n",
        "        continue\n",
        "      else:\n",
        "        if count == 0:\n",
        "          return (\"#\", correct_word[count])\n",
        "        else:\n",
        "          return (correct_word[count-1], correct_word[count])\n",
        "\n",
        "def checkInsert(correct_word, miss_word):\n",
        "  for count, char in enumerate(miss_word):\n",
        "    if count == len(miss_word)-1:\n",
        "      return (miss_word[count-1], char)\n",
        "    else:\n",
        "      if char == correct_word[count]:\n",
        "        continue\n",
        "      else:\n",
        "        if count == 0:\n",
        "          return (\"#\", char)\n",
        "        else:\n",
        "          return (miss_word[count-1], char)\n",
        "\n",
        "def checkSubsitute(correct_word, miss_word):\n",
        "  for count, char in enumerate(miss_word):\n",
        "    if char == correct_word[count]:\n",
        "      continue\n",
        "    else:\n",
        "      if count != len(miss_word)-1:\n",
        "        if char == correct_word[count+1] and correct_word[count] == miss_word[count+1]:\n",
        "          return None\n",
        "      return (correct_word[count], char)\n",
        "\n",
        "def checkTranspose(correct_word, miss_word):\n",
        "  for count, char in enumerate(miss_word):\n",
        "    if char == correct_word[count]:\n",
        "      continue\n",
        "    else:\n",
        "      if char == correct_word[count+1] and correct_word[count] == miss_word[count+1]:\n",
        "        return (correct_word[count], char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt_1DIv7Ebg9"
      },
      "source": [
        "def findFunction(correct_word, miss_word):\n",
        "  # Deletion\n",
        "  if len(miss_word) < len(correct_word):\n",
        "    return \"delete\", checkDelete(correct_word, miss_word)  \n",
        "  \n",
        "  # Insertion\n",
        "  elif len(miss_word) > len(correct_word):\n",
        "    return \"insert\", checkInsert(correct_word, miss_word)\n",
        "  \n",
        "  # Subsitute Or Transpose\n",
        "  elif len(miss_word) == len(correct_word):\n",
        "    if checkSubsitute(correct_word, miss_word):\n",
        "      return \"subsitute\", checkSubsitute(correct_word, miss_word)\n",
        "    else:\n",
        "      return \"transpose\", checkTranspose(correct_word, miss_word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XaBoOzYj2rz"
      },
      "source": [
        "**Finding most probable word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V736WOQIBKLJ"
      },
      "source": [
        "def spellCorrection(miss_word):\n",
        "  word_dict = dict()\n",
        "  candidate_words = findCandidateWords(miss_word)\n",
        "  if len(candidate_words) == 0:\n",
        "    return miss_word\n",
        "  else:\n",
        "    for correct_word in candidate_words:\n",
        "      mode, char_tuple = findFunction(correct_word, miss_word)\n",
        "      bayes_prob = calcErrorProbability(char_tuple, mode) * unigrams[correct_word]    # Equation: P(w|x) . P(w)\n",
        "      word_dict[correct_word] = bayes_prob\n",
        "\n",
        "    correct_guess = max(word_dict, key = word_dict.get)   # Arg Max from the dictionary of words with their probabilities\n",
        "  \n",
        "  print(word_dict)\n",
        "  return correct_guess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "TdDHms90UvUJ",
        "outputId": "f1893a8d-3cff-489a-822b-69b5499af8d8"
      },
      "source": [
        "spellCorrection(\"hello\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hell': 6.429668860835294e-11, 'helly': 2.411875342086612e-10, 'ello': 5.41310545710595e-11}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'helly'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    }
  ]
}