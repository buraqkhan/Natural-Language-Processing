{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Buraq Khan\n",
    "\n",
    "### Email: i180800@nu.edu.pk\n",
    "\n",
    "### Roll num: i180800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expand each heading to see working*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_doc = \"\"\n",
    "count_fake = 0 \n",
    "for filename in os.listdir('data/Train/Fake'):\n",
    "    count_fake += 1\n",
    "    with open(os.path.join('data/Train/Fake', filename), 'r') as f:\n",
    "        fake_doc += f.read()\n",
    "        f.close()\n",
    "\n",
    "real_doc = \"\"\n",
    "count_real = 0 \n",
    "for filename in os.listdir('data/Train/Real'):\n",
    "    count_real += 1\n",
    "    with open(os.path.join('data/Train/Real', filename), 'r') as f:\n",
    "        real_doc += f.read()\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_doc = re.sub('\\s+', ' ', fake_doc)\n",
    "real_doc = re.sub('\\s+', ' ', real_doc)\n",
    "#count_fake\n",
    "count_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/stopwords-ur.txt\", \"r\")\n",
    "stop_words = f.readlines()\n",
    "\n",
    "for count, word in enumerate(stop_words):\n",
    "    word = re.sub(\"\\s+\", \"\", word)\n",
    "    stop_words[count] = word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_fake_list = []\n",
    "for filename in os.listdir('data/Train/Fake'):\n",
    "    with open(os.path.join('data/Train/Fake', filename), 'r') as f:\n",
    "        dup_fake_list.append(f.read())\n",
    "        f.close()\n",
    "\n",
    "dup_real_list = []\n",
    "for filename in os.listdir('data/Train/Real'):\n",
    "    with open(os.path.join('data/Train/Real', filename), 'r') as f:\n",
    "        dup_real_list.append(f.read())\n",
    "        f.close()\n",
    "\n",
    "for count, text in enumerate(dup_fake_list):\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    dup_fake_list[count] = text\n",
    "\n",
    "for count, text in enumerate(dup_real_list):\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    dup_real_list[count] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicates\n",
    "dup_fake = \"\"\n",
    "for text in dup_fake_list:\n",
    "    l = text.split()\n",
    "    k = []\n",
    "    for word in l:\n",
    "        if (text.count(word)>1 and (word not in k) or text.count(word)==1):\n",
    "            k.append(word) \n",
    "    dup_fake += ' '.join(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_real = \"\"\n",
    "for text in dup_real_list:\n",
    "    l = text.split()\n",
    "    k = []\n",
    "    for word in l:\n",
    "        if (text.count(word)>1 and (word not in k) or text.count(word)==1):\n",
    "            k.append(word) \n",
    "    dup_real += ' '.join(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning through Naive Bayes (Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45141065830721006 0.54858934169279\n"
     ]
    }
   ],
   "source": [
    "fake_prior = count_fake / (count_fake + count_real)\n",
    "real_prior = count_real / (count_fake + count_real)\n",
    "print(fake_prior, real_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Word occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the occurence of each word in fake doc\n",
    "fake_occur = {}\n",
    "l = fake_doc.split()\n",
    "for word in l:\n",
    "    if word not in fake_occur.keys():\n",
    "        fake_occur[word] = 1\n",
    "    else:\n",
    "        fake_occur[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_occur = {}\n",
    "l = real_doc.split()\n",
    "for word in l:\n",
    "    if word not in real_occur.keys():\n",
    "        real_occur[word] = 1\n",
    "    else:\n",
    "        real_occur[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "text = real_doc + fake_doc\n",
    "text_list = text.split()\n",
    "for word in text_list:\n",
    "    if word not in vocabulary:\n",
    "        vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16036"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the occurence of each word in fake doc\n",
    "fake_occur_sw = {}\n",
    "l = fake_doc.split()\n",
    "for word in l:\n",
    "    if word not in stop_words:\n",
    "        if word not in fake_occur_sw.keys():\n",
    "            fake_occur_sw[word] = 1\n",
    "        else:\n",
    "            fake_occur_sw[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_occur_sw = {}\n",
    "l = real_doc.split()\n",
    "for word in l:\n",
    "    if word not in stop_words:\n",
    "        if word not in real_occur_sw.keys():\n",
    "            real_occur_sw[word] = 1\n",
    "        else:\n",
    "            real_occur_sw[word] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_fake_dict = {}\n",
    "l = dup_fake.split()\n",
    "for word in l:\n",
    "    if word not in dup_fake_dict.keys():\n",
    "        dup_fake_dict[word] = 1\n",
    "    else:\n",
    "        dup_fake_dict[word] += 1\n",
    "\n",
    "# for key, val in dup_fake_dict.items():\n",
    "#     print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_real_dict = {}\n",
    "l = dup_real.split()\n",
    "for word in l:\n",
    "    if word not in dup_real_dict.keys():\n",
    "        dup_real_dict[word] = 1\n",
    "    else:\n",
    "        dup_real_dict[word] += 1\n",
    "\n",
    "# for key, val in dup_real_dict.items():\n",
    "#     print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Negation Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_words = ['نہیں', 'نہ']\n",
    "fake_dict_neg = {}\n",
    "real_dict_neg = {}\n",
    "for key, val in fake_occur.items():\n",
    "    if key not in negation_words:\n",
    "        fake_dict_neg[key] = val\n",
    "for key, val in real_occur.items():\n",
    "    if key not in negation_words:\n",
    "        real_dict_neg[key] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probabilities (using Laplace Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcNBFake(fake_dict, vocab):\n",
    "    prob_fake = {}\n",
    "    for word in vocab:\n",
    "        if word in fake_dict.keys():\n",
    "            prob_fake[word] = (fake_dict[word] + 1) / (len(fake_dict.keys()) + len(vocab))  # laplace smoothing\n",
    "        else:\n",
    "            prob_fake[word] = 1 / (len(fake_dict.keys()) + len(vocab))\n",
    "    return prob_fake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcNBReal(real_dict, vocab):\n",
    "    prob_real = {}\n",
    "    for word in vocab:\n",
    "        if word in real_dict.keys():\n",
    "            prob_real[word] = (real_dict[word] + 1) / (len(real_dict.keys()) + len(vocab))\n",
    "        else:\n",
    "            prob_real[word] = 1 / (len(real_dict.keys()) + len(vocab))\n",
    "\n",
    "    return prob_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_prob = calcNBFake(fake_occur, vocabulary)\n",
    "real_prob = calcNBReal(real_occur, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_prob_sw = calcNBFake(fake_occur_sw, vocabulary)\n",
    "real_prob_sw = calcNBReal(real_occur_sw, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_real_prob = calcNBReal(dup_real_dict, vocabulary)\n",
    "dup_fake_prob = calcNBFake(dup_fake_dict, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_prob_neg = calcNBFake(fake_dict_neg, vocabulary)\n",
    "real_prob_neg = calcNBReal(real_dict_neg, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBTest(real_prior, fake_prior, real_prob, fake_prob, test_words):\n",
    "    fake_score = math.log(fake_prior) + 10\n",
    "    real_score = math.log(real_prior)\n",
    "    for word in test_words:\n",
    "        if word in vocabulary:\n",
    "            fake_score += math.log(fake_prob[word])\n",
    "            real_score += math.log(real_prob[word])\n",
    "    \n",
    "    if fake_score > real_score:\n",
    "        return \"Fake\"\n",
    "    else:\n",
    "        return \"Real\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/Test/Fake/tch71.txt', \"r\")\n",
    "test = f.read()\n",
    "idk = test.split()\n",
    "words = []\n",
    "words_sw = []\n",
    "for word in idk:\n",
    "    if word not in words:\n",
    "        words.append(word)\n",
    "    if word not in words_sw and word not in stop_words:\n",
    "        words_sw.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Real'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBTest(real_prior, fake_prior, real_prob, fake_prob, words)\n",
    "#NBTest(real_prior, fake_prior, real_prob_sw, fake_prob_sw, words_sw)\n",
    "#NBTest(real_prior, fake_prior, dup_real_prob, dup_fake_prob, words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcReal(r_prior, f_prior, r_prob, f_prob):\n",
    "    total_real = 0\n",
    "    true_real = 0 \n",
    "    false_fake = 0\n",
    "    for filename in os.listdir('data/Test/Real'):\n",
    "        total_real += 1\n",
    "        with open(os.path.join('data/Test/Real', filename), 'r') as f:\n",
    "            text = f.read()\n",
    "            f.close()\n",
    "        \n",
    "        text_words = text.split()\n",
    "        result = NBTest(r_prior, f_prior, r_prob, f_prob, text_words)\n",
    "        if result == \"Real\":\n",
    "            true_real += 1\n",
    "        else:\n",
    "            false_fake += 1\n",
    "    \n",
    "    return total_real, true_real, false_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFake(r_prior, f_prior, r_prob, f_prob):\n",
    "    total_fake = 0\n",
    "    true_fake = 0 \n",
    "    false_real = 0\n",
    "    for filename in os.listdir('data/Test/Fake'):\n",
    "        total_fake += 1\n",
    "        with open(os.path.join('data/Test/Fake', filename), 'r') as f:\n",
    "            text = f.read()\n",
    "            f.close()\n",
    "        \n",
    "        text_words = text.split()\n",
    "        result = NBTest(r_prior, f_prior, r_prob, f_prob, text_words)\n",
    "        if result == \"Fake\":\n",
    "            true_fake += 1\n",
    "        else:\n",
    "            false_real += 1\n",
    "    \n",
    "    return total_fake, true_fake, false_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(tr, tf, fr, ff):\n",
    "    return (tr + tf) / (tr + tf + fr + ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(tp, fp):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "p = Precision(true_real, false_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(tp, fn):\n",
    "    return tp / (fn + tp)\n",
    "\n",
    "r = Recall(true_real, false_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(precision, recall):\n",
    "    return (2 * precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testing(r_prob, f_prob):\n",
    "    total_real, true_real, false_fake = calcReal(real_prior, fake_prior, r_prob, f_prob)\n",
    "    total_fake, true_fake, false_real = calcFake(real_prior, fake_prior, r_prob, f_prob)\n",
    "    \n",
    "    accuracy = Accuracy(true_real, true_fake, false_real, false_fake)\n",
    "    \n",
    "    precision_real = Precision(true_real, false_real)\n",
    "    precision_fake = Precision(true_fake, false_fake)\n",
    "    \n",
    "    recall_real = Recall(true_real, false_fake)\n",
    "    recall_fake = Recall(true_fake, false_real)\n",
    "\n",
    "    F1_real = F1(precision_real, recall_real)\n",
    "    F1_fake = F1(precision_fake, recall_fake)\n",
    "\n",
    "    return accuracy, precision_real, precision_fake, recall_real, recall_fake, F1_real, F1_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(r_prob, f_prob):\n",
    "    accuracy, precision_real, precision_fake, recall_real, recall_fake, F1_real, F1_fake = Testing(r_prob, f_prob)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision of real class: \", precision_real)\n",
    "    print(\"Precision of fake class: \", precision_fake)\n",
    "    print(\"Recall of real class: \", recall_real)\n",
    "    print(\"Recall of fake class: \", recall_fake)\n",
    "    print(\"F1 of real class: \", F1_real)\n",
    "    print(\"F1 of fake class: \", F1_fake)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Stop Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Text Classifier with stop words included\n",
      "Accuracy:  0.5954198473282443\n",
      "Precision of real class:  0.5859375\n",
      "Precision of fake class:  1.0\n",
      "Recall of real class:  1.0\n",
      "Recall of fake class:  0.05357142857142857\n",
      "F1 of real class:  0.7389162561576355\n",
      "F1 of fake class:  0.10169491525423728\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of Text Classifier with stop words included\")\n",
    "output(real_prob, fake_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Text Classifier without stop words included\n",
      "Accuracy:  0.6679389312977099\n",
      "Precision of real class:  0.6375545851528385\n",
      "Precision of fake class:  0.8787878787878788\n",
      "Recall of real class:  0.9733333333333334\n",
      "Recall of fake class:  0.25892857142857145\n",
      "F1 of real class:  0.770448548812665\n",
      "F1 of fake class:  0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of Text Classifier without stop words included\")\n",
    "output(real_prob_sw, fake_prob_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Text Classifier using Boolean Naive Bayes\n",
      "Accuracy:  0.6564885496183206\n",
      "Precision of real class:  0.6293103448275862\n",
      "Precision of fake class:  0.8666666666666667\n",
      "Recall of real class:  0.9733333333333334\n",
      "Recall of fake class:  0.23214285714285715\n",
      "F1 of real class:  0.7643979057591623\n",
      "F1 of fake class:  0.3661971830985915\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of Text Classifier using Boolean Naive Bayes\")\n",
    "output(dup_real_prob, dup_fake_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Removing Negation Words (Bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Text Classifier after removing Negation Words\n",
      "Accuracy:  0.5954198473282443\n",
      "Precision of real class:  0.5859375\n",
      "Precision of fake class:  1.0\n",
      "Recall of real class:  1.0\n",
      "Recall of fake class:  0.05357142857142857\n",
      "F1 of real class:  0.7389162561576355\n",
      "F1 of fake class:  0.10169491525423728\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation of Text Classifier after removing Negation Words\")\n",
    "output(real_prob_neg, fake_prob_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparing Naive Bayes with and without stopwords:**\n",
    "\n",
    "### When we didn't remove stop words from our text, the average accuracy was roughly '59.5%'. Whereas, when we removed the stop words from our text, the average accuracy came to be '66.7%'. As seen clearly, the removal of stop words had an effect on the accuracy.\n",
    "\n",
    "### Furthermore, without the stop words included, there is a significant improvement in the detection of fake news, both *Recall* and *F1* show a large improvement.\n",
    "\n",
    "### From this we can deduce that on average the removal of stop words resulted in sizeable improvement in the correctness of our text classifier in the detection of Fake News.\n",
    "\n",
    "### **Comparing Normal Naive Bayes with Boolean Naive Bayes Classifier:**\n",
    "\n",
    "### Boolean Naive Bayes Classifier performs better at detecting Fake News as compared to Normal Naive Bayes Classifier. This can be seen in the results of Accuracy, Recall and F1. \n",
    "\n",
    "### **Comparing Naive Bayes after removal of Negation words:**\n",
    "\n",
    "### There is very little improvement in the detection of Fake News after removal of Negation Words in comparision with normal data. Although, it seems like if certain phrases that indicated negation were removed in preprocessing it would improve results. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}